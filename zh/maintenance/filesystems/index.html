<!DOCTYPE html>
<html lang="zh" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="

  Filesystems
  #

Apache Paimon utilizes the same pluggable file systems as Apache Flink. Users can follow the
standard plugin mechanism
to configure the plugin structure if using Flink as compute engine. However, for other engines like Spark
or Hive, the provided opt jars (by Flink) may get conflicts and cannot be used directly. It is not convenient
for users to fix class conflicts, thus Paimon provides the self-contained and engine-unified
FileSystem pluggable jars for user to query tables from Spark/Hive side.">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/zh/maintenance/filesystems/">
  <meta property="og:site_name" content="Paimon文档">
  <meta property="og:title" content="Filesystems">
  <meta property="og:description" content="Filesystems#Apache Paimon utilizes the same pluggable file systems as Apache Flink. Users can follow the standard plugin mechanism to configure the plugin structure if using Flink as compute engine. However, for other engines like Spark or Hive, the provided opt jars (by Flink) may get conflicts and cannot be used directly. It is not convenient for users to fix class conflicts, thus Paimon provides the self-contained and engine-unified FileSystem pluggable jars for user to query tables from Spark/Hive side.">
  <meta property="og:locale" content="zh">
  <meta property="og:type" content="article">
    <meta property="article:section" content="maintenance">
<title>Filesystems | Paimon文档</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="http://localhost:1313/zh/maintenance/filesystems/">
  <link rel="alternate" hreflang="en" href="http://localhost:1313/maintenance/filesystems/" title="Filesystems">
<link rel="stylesheet" href="/book.min.d5e59cb0aa8d22a5813c62cd5e25d3d172489a369c61dc3f622ee96ae1ebb457.css" integrity="sha256-1eWcsKqNIqWBPGLNXiXT0XJImjacYdw/Yi7pauHrtFc=" crossorigin="anonymous">
  <script defer src="/fuse.min.js"></script>
  <script defer src="/zh.search.min.0259e16e01f9bf9e62c7f824fe0ec1c165324ea4e5322593215979fa1cca1c0d.js" integrity="sha256-AlnhbgH5v55ix/gk/g7BwWUyTqTlMiWTIVl5&#43;hzKHA0=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/zh/"><span>Paimon文档</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="搜索" aria-label="搜索" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>



  



  
    
  


  


<ul class="book-languages">
  <li>
    <input type="checkbox" id="languages" class="toggle" />
    <label for="languages" class="flex">
      <a role="button" class="flex flex-auto">
        <img src="/svg/translate.svg" class="book-icon" alt="Languages" />
        简体中文
      </a>
    </label>

    <ul>
      
      <li>
        <a href="/maintenance/filesystems/">
          English
        </a>
      </li>
      
    </ul>
  </li>
</ul>














  
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-d9be75c8909d789e72921d17acf02ea8" class="toggle"  />
    <label for="section-d9be75c8909d789e72921d17acf02ea8" class="flex">
      <a href="/zh/concepts/" class="flex-auto ">Concepts</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/basic-concepts/" class="">Basic Concepts</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/concurrency-control/" class="">Concurrency Control</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/catalog/" class="">Catalog</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-deae667da60265cc05d140a12e0f56bc" class="toggle"  />
    <label for="section-deae667da60265cc05d140a12e0f56bc" class="flex">
      <a href="/zh/concepts/rest/" class="flex-auto ">RESTCatalog</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/rest/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/rest/bear/" class="">Bear Token</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/rest/dlf/" class="">DLF Token</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/rest/rest-api/" class="">REST API</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/table-types/" class="">Table Types</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/system-tables/" class="">System Tables</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/data-types/" class="">Data Types</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-6649d7358937a7911f214fa195e4d514" class="toggle"  />
    <label for="section-6649d7358937a7911f214fa195e4d514" class="flex">
      <a href="/zh/concepts/spec/" class="flex-auto ">Specification</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/spec/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/spec/schema/" class="">Schema</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/spec/snapshot/" class="">Snapshot</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/spec/manifest/" class="">Manifest</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/spec/datafile/" class="">DataFile</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/spec/tableindex/" class="">Table Index</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/concepts/spec/fileindex/" class="">File Index</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-116493b962a7709b96d887a67410ae2c" class="toggle"  />
    <label for="section-116493b962a7709b96d887a67410ae2c" class="flex">
      <a href="/zh/primary-key-table/" class="flex-auto ">Table with PK</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/zh/primary-key-table/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/primary-key-table/data-distribution/" class="">Data Distribution</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/primary-key-table/table-mode/" class="">Table Mode</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-e2b73115efcda305a99daf2e913ad177" class="toggle"  />
    <label for="section-e2b73115efcda305a99daf2e913ad177" class="flex">
      <a href="/zh/primary-key-table/merge-engine/" class="flex-auto ">Merge Engine</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/zh/primary-key-table/merge-engine/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/primary-key-table/merge-engine/partial-update/" class="">Partial Update</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/primary-key-table/merge-engine/aggregation/" class="">Aggregation</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/primary-key-table/merge-engine/first-row/" class="">First Row</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/primary-key-table/changelog-producer/" class="">Changelog Producer</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/primary-key-table/sequence-rowkind/" class="">Sequence &amp; Rowkind</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/primary-key-table/compaction/" class="">Compaction</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/primary-key-table/query-performance/" class="">Query Performance</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-b0736f3589d2982eb8482a699fc8a2eb" class="toggle"  />
    <label for="section-b0736f3589d2982eb8482a699fc8a2eb" class="flex">
      <a href="/zh/append-table/" class="flex-auto ">Table w/o PK</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/zh/append-table/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/append-table/streaming/" class="">Streaming</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/append-table/query-performance/" class="">Query Performance</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/append-table/update/" class="">Update</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/append-table/bucketed/" class="">Bucketed</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-f8931a786680e7034fab37b5fdb5d7f1" class="toggle"  />
    <label for="section-f8931a786680e7034fab37b5fdb5d7f1" class="flex">
      <a href="/zh/flink/" class="flex-auto ">Engine Flink</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/zh/flink/quick-start/" class="">Quick Start</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/flink/sql-ddl/" class="">SQL DDL</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/flink/sql-write/" class="">SQL Write</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/flink/sql-query/" class="">SQL Query</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/flink/consumer-id/" class="">Consumer ID</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/flink/sql-lookup/" class="">SQL Lookup</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/flink/sql-alter/" class="">SQL Alter</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/flink/clone-tables/" class="">Clone Tables</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/flink/procedures/" class="">Procedures</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/flink/action-jars/" class="">Action Jars</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/flink/savepoint/" class="">Savepoint</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ace04d93fdf5d66516b62035c9f23d2f" class="toggle"  />
    <label for="section-ace04d93fdf5d66516b62035c9f23d2f" class="flex">
      <a href="/zh/spark/" class="flex-auto ">Engine Spark</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/zh/spark/quick-start/" class="">Quick Start</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/spark/sql-ddl/" class="">SQL DDL</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/spark/sql-functions/" class="">SQL Functions</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/spark/sql-write/" class="">SQL Write</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/spark/sql-query/" class="">SQL Query</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/spark/sql-alter/" class="">SQL Alter</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/spark/auxiliary/" class="">Auxiliary</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/spark/procedures/" class="">Procedures</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-0c8962b835a7e7ba77e51210ab81d8ab" class="toggle"  />
    <label for="section-0c8962b835a7e7ba77e51210ab81d8ab" class="flex">
      <a href="/zh/ecosystem/" class="flex-auto ">Ecosystem</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/zh/ecosystem/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/ecosystem/starrocks/" class="">StarRocks</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/ecosystem/doris/" class="">Doris</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/ecosystem/hive/" class="">Hive</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/ecosystem/trino/" class="">Trino</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/ecosystem/amoro/" class="">Amoro</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-9b9cc7978eec312dbf5ff8e6fae0a484" class="toggle"  />
    <label for="section-9b9cc7978eec312dbf5ff8e6fae0a484" class="flex">
      <a href="/zh/cdc-ingestion/" class="flex-auto ">CDC Ingestion</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/zh/cdc-ingestion/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/cdc-ingestion/mysql-cdc/" class="">Mysql CDC</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/cdc-ingestion/postgres-cdc/" class="">Postgres CDC</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/cdc-ingestion/kafka-cdc/" class="">Kafka CDC</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/cdc-ingestion/mongo-cdc/" class="">Mongo CDC</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/cdc-ingestion/pulsar-cdc/" class="">Pulsar CDC</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/cdc-ingestion/debezium-bson/" class="">Debezium BSON</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ce3634687657a9574119215326eb830f" class="toggle" checked />
    <label for="section-ce3634687657a9574119215326eb830f" class="flex">
      <a href="/zh/maintenance/" class="flex-auto ">Maintenance</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/zh/maintenance/filesystems/" class="active">Filesystems</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/maintenance/write-performance/" class="">Write Performance</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/maintenance/dedicated-compaction/" class="">Dedicated Compaction</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/maintenance/manage-snapshots/" class="">Manage Snapshots</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/maintenance/rescale-bucket/" class="">Rescale Bucket</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/maintenance/manage-tags/" class="">Manage Tags</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/maintenance/metrics/" class="">Metrics</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/maintenance/manage-privileges/" class="">Manage Privileges</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/maintenance/manage-branches/" class="">Manage Branches</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/maintenance/manage-partitions/" class="">Manage Partitions</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/maintenance/configurations/" class="">Configurations</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-6216b0bad2d424854c2ce0b7a340342a" class="toggle"  />
    <label for="section-6216b0bad2d424854c2ce0b7a340342a" class="flex">
      <a href="/zh/program-api/" class="flex-auto ">Program API</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/zh/program-api/flink-api/" class="">Flink API</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/program-api/java-api/" class="">Java API</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/program-api/catalog-api/" class="">Catalog API</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/program-api/python-api/" class="">Python API</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-3826503c745210e7c6185ec4dbaf177c" class="toggle"  />
    <label for="section-3826503c745210e7c6185ec4dbaf177c" class="flex">
      <a href="/zh/migration/" class="flex-auto ">Migration</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/zh/migration/migration-from-hive/" class="">Migration From Hive</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/migration/migration-from-iceberg/" class="">Migration From Iceberg</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/migration/upsert-to-partitioned/" class="">Upsert To Partitioned</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/migration/iceberg-compatibility/" class="">Iceberg Compatibility</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-c7c447417aa4a80b01c649e7072bc024" class="toggle"  />
    <label for="section-c7c447417aa4a80b01c649e7072bc024" class="flex">
      <a href="/zh/project/" class="flex-auto ">Project</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/zh/project/roadmap/" class="">Roadmap</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/project/download/" class="">Download</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/project/contributing/" class="">Contributing</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/zh/project/committer/" class="">Committer</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cce788b521038a23eeb70f4fdc430011" class="toggle"  />
    <label for="section-cce788b521038a23eeb70f4fdc430011" class="flex">
      <a href="/zh/learn-paimon/" class="flex-auto ">Learn Paimon</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/zh/learn-paimon/understand-files/" class="">Understand Files</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>














</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Filesystems</h3>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>

  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#supported-filesystems">Supported FileSystems</a></li>
    <li><a href="#dependency">Dependency</a></li>
    <li><a href="#hdfs">HDFS</a>
      <ul>
        <li><a href="#hdfs-configuration">HDFS Configuration</a></li>
        <li><a href="#hadoop-compatible-file-systems-hcfs">Hadoop-compatible file systems (HCFS)</a></li>
        <li><a href="#kerberos">Kerberos</a></li>
        <li><a href="#hdfs-ha">HDFS HA</a></li>
        <li><a href="#hdfs-viewfs">HDFS ViewFS</a></li>
      </ul>
    </li>
    <li><a href="#oss">OSS</a></li>
    <li><a href="#s3">S3</a>
      <ul>
        <li><a href="#s3-compliant-object-stores">S3 Compliant Object Stores</a></li>
        <li><a href="#configure-path-style-access">Configure Path Style Access</a></li>
        <li><a href="#s3a-performance">S3A Performance</a></li>
      </ul>
    </li>
    <li><a href="#google-cloud-storage">Google Cloud Storage</a></li>
    <li><a href="#microsoft-azure-storage">Microsoft Azure Storage</a></li>
    <li><a href="#microsoft-azure-storage-1">Microsoft Azure Storage</a></li>
    <li><a href="#obs">OBS</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<h1 id="filesystems">
  Filesystems
  <a class="anchor" href="#filesystems">#</a>
</h1>
<p>Apache Paimon utilizes the same pluggable file systems as Apache Flink. Users can follow the
<a href="https://nightlies.apache.org/flink/flink-docs-stable/docs/deployment/filesystems/plugins/">standard plugin mechanism</a>
to configure the plugin structure if using Flink as compute engine. However, for other engines like Spark
or Hive, the provided opt jars (by Flink) may get conflicts and cannot be used directly. It is not convenient
for users to fix class conflicts, thus Paimon provides the self-contained and engine-unified
FileSystem pluggable jars for user to query tables from Spark/Hive side.</p>
<h2 id="supported-filesystems">
  Supported FileSystems
  <a class="anchor" href="#supported-filesystems">#</a>
</h2>
<table>
  <thead>
      <tr>
          <th style="text-align: left">FileSystem</th>
          <th style="text-align: left">URI Scheme</th>
          <th>Pluggable</th>
          <th style="text-align: left">Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">Local File System</td>
          <td style="text-align: left">file://</td>
          <td>N</td>
          <td style="text-align: left">Built-in Support</td>
      </tr>
      <tr>
          <td style="text-align: left">HDFS</td>
          <td style="text-align: left">hdfs://</td>
          <td>N</td>
          <td style="text-align: left">Built-in Support, ensure that the cluster is in the hadoop environment</td>
      </tr>
      <tr>
          <td style="text-align: left">Aliyun OSS</td>
          <td style="text-align: left">oss://</td>
          <td>Y</td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left">S3</td>
          <td style="text-align: left">s3://</td>
          <td>Y</td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left">Tencent Cloud Object Storage</td>
          <td style="text-align: left">cosn://</td>
          <td>Y</td>
          <td style="text-align: left"></td>
      </tr>
      <tr>
          <td style="text-align: left">Huawei OBS</td>
          <td style="text-align: left">obs://</td>
          <td>Y</td>
          <td style="text-align: left"></td>
      </tr>
  </tbody>
</table>
<h2 id="dependency">
  Dependency
  <a class="anchor" href="#dependency">#</a>
</h2>
<p>We recommend you to download the jar directly: <a href="http://localhost:1313/zh/project/download/#filesystem-jars">Download Link</a>.</p>
<p>You can also manually build bundled jar from the source code.</p>
<p>To build from source code, <a href="https://github.com/apache/paimon.git">clone the git repository</a>.</p>
<p>Build shaded jar with the following command.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mvn clean install -DskipTests
</span></span></code></pre></div><p>You can find the shaded jars under
<code>./paimon-filesystems/paimon-${fs}/target/paimon-${fs}-1.1.1.jar</code>.</p>
<h2 id="hdfs">
  HDFS
  <a class="anchor" href="#hdfs">#</a>
</h2>
<p>You don&rsquo;t need any additional dependencies to access HDFS because you have already taken care of the Hadoop dependencies.</p>
<h3 id="hdfs-configuration">
  HDFS Configuration
  <a class="anchor" href="#hdfs-configuration">#</a>
</h3>
<p>For HDFS, the most important thing is to be able to read your HDFS configuration.</p>





<div class="book-tabs"><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Flink"
    name="tabs-hdfs conf"
    id="tabs-hdfs conf-0"
    checked="checked" 
    onclick="onSwitch('Flink')"
  />
  <label for="tabs-hdfs conf-0">Flink</label>
  <div class="book-tabs-content markdown-inner"><p>You may not have to do anything, if you are in a hadoop environment. Otherwise pick one of the following ways to
configure your HDFS:</p>
<ol>
<li>Set environment variable <code>HADOOP_HOME</code> or <code>HADOOP_CONF_DIR</code>.</li>
<li>Configure <code>'hadoop-conf-dir'</code> in the paimon catalog.</li>
<li>Configure Hadoop options through prefix <code>'hadoop.'</code> in the paimon catalog.</li>
</ol>
<p>The first approach is recommended.</p>
<p>If you do not want to include the value of the environment variable, you can configure <code>hadoop-conf-loader</code> to <code>option</code>.</p>
</div><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Hive/Spark"
    name="tabs-hdfs conf"
    id="tabs-hdfs conf-1"
     
    onclick="onSwitch('Hive\/Spark')"
  />
  <label for="tabs-hdfs conf-1">Hive/Spark</label>
  <div class="book-tabs-content markdown-inner">HDFS Configuration is available directly through the computation cluster, see cluster configuration of Hive and Spark for details.</div></div>

<h3 id="hadoop-compatible-file-systems-hcfs">
  Hadoop-compatible file systems (HCFS)
  <a class="anchor" href="#hadoop-compatible-file-systems-hcfs">#</a>
</h3>
<p>All Hadoop file systems are automatically available when the Hadoop libraries are on the classpath.</p>
<p>This way, Paimon seamlessly supports all of Hadoop file systems implementing the <code>org.apache.hadoop.fs.FileSystem</code>
interface, and all Hadoop-compatible file systems (HCFS).</p>
<ul>
<li>HDFS</li>
<li>Alluxio (see configuration specifics below)</li>
<li>XtreemFS</li>
<li>…</li>
</ul>
<p>The Hadoop configuration has to have an entry for the required file system implementation in the <code>core-site.xml</code> file.</p>
<p>For Alluxio support add the following entry into the core-site.xml file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#f92672">&lt;property&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;name&gt;</span>fs.alluxio.impl<span style="color:#f92672">&lt;/name&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;value&gt;</span>alluxio.hadoop.FileSystem<span style="color:#f92672">&lt;/value&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&lt;/property&gt;</span>
</span></span></code></pre></div><h3 id="kerberos">
  Kerberos
  <a class="anchor" href="#kerberos">#</a>
</h3>





<div class="book-tabs"><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Flink"
    name="tabs-Kerberos"
    id="tabs-Kerberos-0"
    checked="checked" 
    onclick="onSwitch('Flink')"
  />
  <label for="tabs-Kerberos-0">Flink</label>
  <div class="book-tabs-content markdown-inner">It is recommended to use <a href="https://nightlies.apache.org/flink/flink-docs-stable/docs/deployment/security/security-kerberos/">Flink Kerberos Keytab</a>.</div><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Spark"
    name="tabs-Kerberos"
    id="tabs-Kerberos-1"
     
    onclick="onSwitch('Spark')"
  />
  <label for="tabs-Kerberos-1">Spark</label>
  <div class="book-tabs-content markdown-inner">It is recommended to use <a href="https://spark.apache.org/docs/latest/security.html#using-a-keytab">Spark Kerberos Keytab</a>.</div><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Hive"
    name="tabs-Kerberos"
    id="tabs-Kerberos-2"
     
    onclick="onSwitch('Hive')"
  />
  <label for="tabs-Kerberos-2">Hive</label>
  <div class="book-tabs-content markdown-inner">An intuitive approach is to configure Hive&rsquo;s kerberos authentication.</div><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Trino/JavaAPI"
    name="tabs-Kerberos"
    id="tabs-Kerberos-3"
     
    onclick="onSwitch('Trino\/JavaAPI')"
  />
  <label for="tabs-Kerberos-3">Trino/JavaAPI</label>
  <div class="book-tabs-content markdown-inner"><p>Configure the following three options in your catalog configuration:</p>
<ul>
<li>security.kerberos.login.keytab: Absolute path to a Kerberos keytab file that contains the user credentials.
Please make sure it is copied to each machine.</li>
<li>security.kerberos.login.principal: Kerberos principal name associated with the keytab.</li>
<li>security.kerberos.login.use-ticket-cache: True or false, indicates whether to read from your Kerberos ticket cache.</li>
</ul>
<p>For JavaAPI:</p>
<pre tabindex="0"><code>SecurityContext.install(catalogOptions);
</code></pre></div></div>

<h3 id="hdfs-ha">
  HDFS HA
  <a class="anchor" href="#hdfs-ha">#</a>
</h3>
<p>Ensure that <code>hdfs-site.xml</code> and <code>core-site.xml</code> contain the necessary <a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithNFS.html">HA configuration</a>.</p>
<h3 id="hdfs-viewfs">
  HDFS ViewFS
  <a class="anchor" href="#hdfs-viewfs">#</a>
</h3>
<p>Ensure that <code>hdfs-site.xml</code> and <code>core-site.xml</code> contain the necessary <a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/ViewFs.html">ViewFs configuration</a>.</p>
<h2 id="oss">
  OSS
  <a class="anchor" href="#oss">#</a>
</h2>
Download <a href="https://repo.maven.apache.org/maven2/org/apache/paimon/paimon-oss/1.1.1/paimon-oss-1.1.1.jar">paimon-oss-1.1.1.jar</a>.








<div class="book-tabs"><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Flink"
    name="tabs-oss"
    id="tabs-oss-0"
    checked="checked" 
    onclick="onSwitch('Flink')"
  />
  <label for="tabs-oss-0">Flink</label>
  <div class="book-tabs-content markdown-inner"><blockquote class="book-hint info">
<p>If you have already configured <a href="https://nightlies.apache.org/flink/flink-docs-stable/docs/deployment/filesystems/oss/">oss access through Flink</a> (Via Flink FileSystem),
here you can skip the following configuration.</p>
</blockquote>
<p>Put <code>paimon-oss-1.1.1.jar</code> into <code>lib</code> directory of your Flink home, and create catalog:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">CREATE</span> <span style="color:#66d9ef">CATALOG</span> my_catalog <span style="color:#66d9ef">WITH</span> (
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;type&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;paimon&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;warehouse&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;oss://&lt;bucket&gt;/&lt;path&gt;&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;fs.oss.endpoint&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;oss-cn-hangzhou.aliyuncs.com&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;fs.oss.accessKeyId&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;xxx&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;fs.oss.accessKeySecret&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;yyy&#39;</span>
</span></span><span style="display:flex;"><span>);
</span></span></code></pre></div></div><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Spark"
    name="tabs-oss"
    id="tabs-oss-1"
     
    onclick="onSwitch('Spark')"
  />
  <label for="tabs-oss-1">Spark</label>
  <div class="book-tabs-content markdown-inner"><blockquote class="book-hint info">
<p>If you have already configured oss access through Spark (Via Hadoop FileSystem), here you can skip the following configuration.</p>
</blockquote>
<p>Place <code>paimon-oss-1.1.1.jar</code> together with <code>paimon-spark-1.1.1.jar</code> under Spark&rsquo;s jars directory, and start like</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>spark-sql <span style="color:#ae81ff">\ </span>
</span></span><span style="display:flex;"><span>  --conf spark.sql.catalog.paimon<span style="color:#f92672">=</span>org.apache.paimon.spark.SparkCatalog <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --conf spark.sql.catalog.paimon.warehouse<span style="color:#f92672">=</span>oss://&lt;bucket&gt;/&lt;path&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --conf spark.sql.catalog.paimon.fs.oss.endpoint<span style="color:#f92672">=</span>oss-cn-hangzhou.aliyuncs.com <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --conf spark.sql.catalog.paimon.fs.oss.accessKeyId<span style="color:#f92672">=</span>xxx <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --conf spark.sql.catalog.paimon.fs.oss.accessKeySecret<span style="color:#f92672">=</span>yyy
</span></span></code></pre></div></div><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Hive"
    name="tabs-oss"
    id="tabs-oss-2"
     
    onclick="onSwitch('Hive')"
  />
  <label for="tabs-oss-2">Hive</label>
  <div class="book-tabs-content markdown-inner"><blockquote class="book-hint info">
<p>If you have already configured oss access through Hive (Via Hadoop FileSystem), here you can skip the following configuration.</p>
</blockquote>
<p>NOTE: You need to ensure that Hive metastore can access <code>oss</code>.</p>
<p>Place <code>paimon-oss-1.1.1.jar</code> together with <code>paimon-hive-connector-1.1.1.jar</code> under Hive&rsquo;s auxlib directory, and start like</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">SET</span> paimon.fs.oss.endpoint<span style="color:#f92672">=</span>oss<span style="color:#f92672">-</span>cn<span style="color:#f92672">-</span>hangzhou.aliyuncs.com;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">SET</span> paimon.fs.oss.accessKeyId<span style="color:#f92672">=</span>xxx;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">SET</span> paimon.fs.oss.accessKeySecret<span style="color:#f92672">=</span>yyy;
</span></span></code></pre></div><p>And read table from hive metastore, table can be created by Flink or Spark, see <a href="http://localhost:1313/zh/flink/sql-ddl/">Catalog with Hive Metastore</a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> test_table;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">SELECT</span> <span style="color:#66d9ef">COUNT</span>(<span style="color:#ae81ff">1</span>) <span style="color:#66d9ef">FROM</span> test_table;
</span></span></code></pre></div></div><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Trino"
    name="tabs-oss"
    id="tabs-oss-3"
     
    onclick="onSwitch('Trino')"
  />
  <label for="tabs-oss-3">Trino</label>
  <div class="book-tabs-content markdown-inner"><p>From version 0.8, paimon-trino uses trino filesystem as basic file read and write system. We strongly recommend you to use jindo-sdk in trino.</p>
<p>You can find <a href="https://github.com/aliyun/alibabacloud-jindodata/blob/master/docs/user/4.x/4.6.x/4.6.12/oss/presto/jindosdk_on_presto.md">How to config jindo sdk on trino</a> here.
Please note that:</p>
<ul>
<li>Use paimon to replace hive-hadoop2 when you decompress the plugin jar and find location to put in.</li>
<li>You can specify the <code>core-site.xml</code> in <code>paimon.properties</code> on configuration <a href="https://trino.io/docs/current/connector/hive.html#hdfs-configuration">hive.config.resources</a>.</li>
<li>Presto and Jindo use the same configuration method.</li>
</ul>
</div></div>

<p>If you environment has jindo sdk dependencies, you can use Jindo Fs to connect OSS. Jindo has better read and write efficiency.</p>
<p>Download <a href="https://repo.maven.apache.org/maven2/org/apache/paimon/paimon-jindo/1.1.1/paimon-jindo-1.1.1.jar">paimon-jindo-1.1.1.jar</a>.


</p>
<h2 id="s3">
  S3
  <a class="anchor" href="#s3">#</a>
</h2>
Download <a href="https://repo.maven.apache.org/maven2/org/apache/paimon/paimon-s3/1.1.1/paimon-s3-1.1.1.jar">paimon-s3-1.1.1.jar</a>.








<div class="book-tabs"><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Flink"
    name="tabs-s3"
    id="tabs-s3-0"
    checked="checked" 
    onclick="onSwitch('Flink')"
  />
  <label for="tabs-s3-0">Flink</label>
  <div class="book-tabs-content markdown-inner"><blockquote class="book-hint info">
<p>If you have already configured <a href="https://nightlies.apache.org/flink/flink-docs-stable/docs/deployment/filesystems/s3/">s3 access through Flink</a> (Via Flink FileSystem),
here you can skip the following configuration.</p>
</blockquote>
<p>Put <code>paimon-s3-1.1.1.jar</code> into <code>lib</code> directory of your Flink home, and create catalog:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">CREATE</span> <span style="color:#66d9ef">CATALOG</span> my_catalog <span style="color:#66d9ef">WITH</span> (
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;type&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;paimon&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;warehouse&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;s3://&lt;bucket&gt;/&lt;path&gt;&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;s3.endpoint&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;your-endpoint-hostname&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;s3.access-key&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;xxx&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;s3.secret-key&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;yyy&#39;</span>
</span></span><span style="display:flex;"><span>);
</span></span></code></pre></div></div><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Spark"
    name="tabs-s3"
    id="tabs-s3-1"
     
    onclick="onSwitch('Spark')"
  />
  <label for="tabs-s3-1">Spark</label>
  <div class="book-tabs-content markdown-inner"><blockquote class="book-hint info">
<p>If you have already configured s3 access through Spark (Via Hadoop FileSystem), here you can skip the following configuration.</p>
</blockquote>
<p>Place <code>paimon-s3-1.1.1.jar</code> together with <code>paimon-spark-1.1.1.jar</code> under Spark&rsquo;s jars directory, and start like</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>spark-sql <span style="color:#ae81ff">\ </span>
</span></span><span style="display:flex;"><span>  --conf spark.sql.catalog.paimon<span style="color:#f92672">=</span>org.apache.paimon.spark.SparkCatalog <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --conf spark.sql.catalog.paimon.warehouse<span style="color:#f92672">=</span>s3://&lt;bucket&gt;/&lt;path&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --conf spark.sql.catalog.paimon.s3.endpoint<span style="color:#f92672">=</span>your-endpoint-hostname <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --conf spark.sql.catalog.paimon.s3.access-key<span style="color:#f92672">=</span>xxx <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --conf spark.sql.catalog.paimon.s3.secret-key<span style="color:#f92672">=</span>yyy
</span></span></code></pre></div></div><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Hive"
    name="tabs-s3"
    id="tabs-s3-2"
     
    onclick="onSwitch('Hive')"
  />
  <label for="tabs-s3-2">Hive</label>
  <div class="book-tabs-content markdown-inner"><blockquote class="book-hint info">
<p>If you have already configured s3 access through Hive ((Via Hadoop FileSystem)), here you can skip the following configuration.</p>
</blockquote>
<p>NOTE: You need to ensure that Hive metastore can access <code>s3</code>.</p>
<p>Place <code>paimon-s3-1.1.1.jar</code> together with <code>paimon-hive-connector-1.1.1.jar</code> under Hive&rsquo;s auxlib directory, and start like</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">SET</span> paimon.s3.endpoint<span style="color:#f92672">=</span>your<span style="color:#f92672">-</span>endpoint<span style="color:#f92672">-</span>hostname;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">SET</span> paimon.s3.<span style="color:#66d9ef">access</span><span style="color:#f92672">-</span><span style="color:#66d9ef">key</span><span style="color:#f92672">=</span>xxx;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">SET</span> paimon.s3.secret<span style="color:#f92672">-</span><span style="color:#66d9ef">key</span><span style="color:#f92672">=</span>yyy;
</span></span></code></pre></div><p>And read table from hive metastore, table can be created by Flink or Spark, see <a href="http://localhost:1313/zh/flink/sql-ddl/">Catalog with Hive Metastore</a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> test_table;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">SELECT</span> <span style="color:#66d9ef">COUNT</span>(<span style="color:#ae81ff">1</span>) <span style="color:#66d9ef">FROM</span> test_table;
</span></span></code></pre></div></div><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Trino"
    name="tabs-s3"
    id="tabs-s3-3"
     
    onclick="onSwitch('Trino')"
  />
  <label for="tabs-s3-3">Trino</label>
  <div class="book-tabs-content markdown-inner"><p>Paimon use shared trino filesystem as basic read and write system.</p>
<p>Please refer to <a href="https://trino.io/docs/current/object-storage/file-system-s3.html">Trino S3</a> to config s3 filesystem in trino.</p>
</div></div>

<h3 id="s3-compliant-object-stores">
  S3 Compliant Object Stores
  <a class="anchor" href="#s3-compliant-object-stores">#</a>
</h3>
<p>The S3 Filesystem also support using S3 compliant object stores such as MinIO, Tencent&rsquo;s COS and IBM’s Cloud Object
Storage. Just configure your endpoint to the provider of the object store service.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">s3.endpoint</span>: <span style="color:#ae81ff">your-endpoint-hostname</span>
</span></span></code></pre></div><h3 id="configure-path-style-access">
  Configure Path Style Access
  <a class="anchor" href="#configure-path-style-access">#</a>
</h3>
<p>Some S3 compliant object stores might not have virtual host style addressing enabled by default, for example when using Standalone MinIO for testing purpose.
In such cases, you will have to provide the property to enable path style access.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">s3.path.style.access</span>: <span style="color:#66d9ef">true</span>
</span></span></code></pre></div><h3 id="s3a-performance">
  S3A Performance
  <a class="anchor" href="#s3a-performance">#</a>
</h3>
<p><a href="https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/performance.html">Tune Performance</a> for <code>S3AFileSystem</code>.</p>
<p>If you encounter the following exception:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>Caused by: org.apache.http.conn.ConnectionPoolTimeoutException: Timeout waiting <span style="color:#66d9ef">for</span> connection from pool.
</span></span></code></pre></div><p>Try to configure this in catalog options: <code>fs.s3a.connection.maximum=1000</code>.</p>
<h2 id="google-cloud-storage">
  Google Cloud Storage
  <a class="anchor" href="#google-cloud-storage">#</a>
</h2>
Download <a href="https://repo.maven.apache.org/maven2/org/apache/paimon/paimon-gs/1.1.1/paimon-gs-1.1.1.jar">paimon-gs-1.1.1.jar</a>.








<div class="book-tabs"><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Flink"
    name="tabs-gs"
    id="tabs-gs-0"
    checked="checked" 
    onclick="onSwitch('Flink')"
  />
  <label for="tabs-gs-0">Flink</label>
  <div class="book-tabs-content markdown-inner"><blockquote class="book-hint info">
<p>If you have already configured <a href="https://nightlies.apache.org/flink/flink-docs-release-2.0/docs/deployment/filesystems/gcs/">oss access through Flink</a> (Via Flink FileSystem),
here you can skip the following configuration.</p>
</blockquote>
<p>Put <code>paimon-gs-1.1.1.jar</code> into <code>lib</code> directory of your Flink home, and create catalog:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">CREATE</span> <span style="color:#66d9ef">CATALOG</span> my_catalog <span style="color:#66d9ef">WITH</span> (
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;type&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;paimon&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;warehouse&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;oss://&lt;bucket&gt;/&lt;path&gt;&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;fs.gs.auth.type&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;SERVICE_ACCOUNT_JSON_KEYFILE&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;fs.gs.auth.service.account.json.keyfile&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;/path/to/service-account-.json&#39;</span>
</span></span><span style="display:flex;"><span>);
</span></span></code></pre></div></div></div>

<h2 id="microsoft-azure-storage">
  Microsoft Azure Storage
  <a class="anchor" href="#microsoft-azure-storage">#</a>
</h2>
Download <a href="https://repo.maven.apache.org/maven2/org/apache/paimon/paimon-gs/1.1.1/paimon-gs-1.1.1.jar">paimon-azure-1.1.1.jar</a>.








<div class="book-tabs"><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Flink"
    name="tabs-gs"
    id="tabs-gs-0"
    checked="checked" 
    onclick="onSwitch('Flink')"
  />
  <label for="tabs-gs-0">Flink</label>
  <div class="book-tabs-content markdown-inner"><blockquote class="book-hint info">
<p>If you have already configured <a href="https://nightlies.apache.org/flink/flink-docs-release-2.0/docs/deployment/filesystems/gcs/">oss access through Flink</a> (Via Flink FileSystem),
here you can skip the following configuration.</p>
</blockquote>
<p>Put <code>paimon-gs-1.1.1.jar</code> into <code>lib</code> directory of your Flink home, and create catalog:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">CREATE</span> <span style="color:#66d9ef">CATALOG</span> my_catalog <span style="color:#66d9ef">WITH</span> (
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;type&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;paimon&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;warehouse&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;oss://&lt;bucket&gt;/&lt;path&gt;&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;fs.gs.auth.type&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;SERVICE_ACCOUNT_JSON_KEYFILE&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;fs.gs.auth.service.account.json.keyfile&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;/path/to/service-account-.json&#39;</span>
</span></span><span style="display:flex;"><span>);
</span></span></code></pre></div></div></div>

<h2 id="microsoft-azure-storage-1">
  Microsoft Azure Storage
  <a class="anchor" href="#microsoft-azure-storage-1">#</a>
</h2>
Download <a href="https://repo.maven.apache.org/maven2/org/apache/paimon/paimon-azure/1.1.1/paimon-azure-1.1.1.jar">paimon-azure-1.1.1.jar</a>.








<div class="book-tabs"><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Flink"
    name="tabs-azure"
    id="tabs-azure-0"
    checked="checked" 
    onclick="onSwitch('Flink')"
  />
  <label for="tabs-azure-0">Flink</label>
  <div class="book-tabs-content markdown-inner"><blockquote class="book-hint info">
<p>If you have already configured <a href="https://nightlies.apache.org/flink/flink-docs-release-2.0/docs/deployment/filesystems/azure/">azure access through Flink</a> (Via Flink FileSystem),
here you can skip the following configuration.</p>
</blockquote>
<p>Put <code>paimon-azure-1.1.1.jar</code> into <code>lib</code> directory of your Flink home, and create catalog:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">CREATE</span> <span style="color:#66d9ef">CATALOG</span> my_catalog <span style="color:#66d9ef">WITH</span> (
</span></span><span style="display:flex;"><span>   <span style="color:#e6db74">&#39;type&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;paimon&#39;</span>,
</span></span><span style="display:flex;"><span>   <span style="color:#e6db74">&#39;warehouse&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;wasb://,&lt;container&gt;@&lt;account&gt;.blob.core.windows.net/&lt;path&gt;&#39;</span>,
</span></span><span style="display:flex;"><span>   <span style="color:#e6db74">&#39;fs.azure.account.key.Account.blob.core.windows.net&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;yyy&#39;</span>
</span></span><span style="display:flex;"><span>);
</span></span></code></pre></div></div><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Spark"
    name="tabs-azure"
    id="tabs-azure-1"
     
    onclick="onSwitch('Spark')"
  />
  <label for="tabs-azure-1">Spark</label>
  <div class="book-tabs-content markdown-inner"><blockquote class="book-hint info">
<p>If you have already configured azure access through Spark (Via Hadoop FileSystem), here you can skip the following configuration.</p>
</blockquote>
<p>Place <code>paimon-azure-1.1.1.jar</code> together with <code>paimon-spark-1.1.1.jar</code> under Spark&rsquo;s jars directory, and start like</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>spark-sql <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --conf spark.sql.catalog.paimon<span style="color:#f92672">=</span>org.apache.paimon.spark.SparkCatalog <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --conf spark.sql.catalog.paimon.warehouse<span style="color:#f92672">=</span>wasb://,&lt;container&gt;@&lt;account&gt;.blob.core.windows.net/&lt;path&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --conf fs.azure.account.key.Account.blob.core.windows.net<span style="color:#f92672">=</span>yyy <span style="color:#ae81ff">\
</span></span></span></code></pre></div></div></div>

<h2 id="obs">
  OBS
  <a class="anchor" href="#obs">#</a>
</h2>
Download <a href="https://repo.maven.apache.org/maven2/org/apache/paimon/paimon-obs/1.1.1/paimon-obs-1.1.1.jar">paimon-obs-1.1.1.jar</a>.








<div class="book-tabs"><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Flink"
    name="tabs-obs"
    id="tabs-obs-0"
    checked="checked" 
    onclick="onSwitch('Flink')"
  />
  <label for="tabs-obs-0">Flink</label>
  <div class="book-tabs-content markdown-inner"><blockquote class="book-hint info">
<p>If you have already configured <a href="https://nightlies.apache.org/flink/flink-docs-stable/docs/deployment/filesystems/s3/">obs access through Flink</a> (Via Flink FileSystem),
here you can skip the following configuration.</p>
</blockquote>
<p>Put <code>paimon-obs-1.1.1.jar</code> into <code>lib</code> directory of your Flink home, and create catalog:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">CREATE</span> <span style="color:#66d9ef">CATALOG</span> my_catalog <span style="color:#66d9ef">WITH</span> (
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;type&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;paimon&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;warehouse&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;obs://&lt;bucket&gt;/&lt;path&gt;&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;fs.obs.endpoint&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;obs-endpoint-hostname&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;fs.obs.access.key&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;xxx&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;fs.obs.secret.key&#39;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;yyy&#39;</span>
</span></span><span style="display:flex;"><span>);
</span></span></code></pre></div></div><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Spark"
    name="tabs-obs"
    id="tabs-obs-1"
     
    onclick="onSwitch('Spark')"
  />
  <label for="tabs-obs-1">Spark</label>
  <div class="book-tabs-content markdown-inner"><blockquote class="book-hint info">
<p>If you have already configured obs access through Spark (Via Hadoop FileSystem), here you can skip the following configuration.</p>
</blockquote>
<p>Place <code>paimon-obs-1.1.1.jar</code> together with <code>paimon-spark-1.1.1.jar</code> under Spark&rsquo;s jars directory, and start like</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>spark-sql <span style="color:#ae81ff">\ </span>
</span></span><span style="display:flex;"><span>  --conf spark.sql.catalog.paimon<span style="color:#f92672">=</span>org.apache.paimon.spark.SparkCatalog <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --conf spark.sql.catalog.paimon.warehouse<span style="color:#f92672">=</span>obs://&lt;bucket&gt;/&lt;path&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --conf spark.sql.catalog.paimon.fs.obs.endpoint<span style="color:#f92672">=</span>obs-endpoint-hostname <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --conf spark.sql.catalog.paimon.fs.obs.access.key<span style="color:#f92672">=</span>xxx <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  --conf spark.sql.catalog.paimon.fs.obs.secret.key<span style="color:#f92672">=</span>yyy
</span></span></code></pre></div></div><input 
    type="radio"
    class="toggle"
    data-tab-group="flink-tabs"
    data-tab-item="Hive"
    name="tabs-obs"
    id="tabs-obs-2"
     
    onclick="onSwitch('Hive')"
  />
  <label for="tabs-obs-2">Hive</label>
  <div class="book-tabs-content markdown-inner"><blockquote class="book-hint info">
<p>If you have already configured obs access through Hive ((Via Hadoop FileSystem)), here you can skip the following configuration.</p>
</blockquote>
<p>NOTE: You need to ensure that Hive metastore can access <code>obs</code>.</p>
<p>Place <code>paimon-obs-1.1.1.jar</code> together with <code>paimon-hive-connector-1.1.1.jar</code> under Hive&rsquo;s auxlib directory, and start like</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">SET</span> paimon.fs.obs.endpoint<span style="color:#f92672">=</span>obs<span style="color:#f92672">-</span>endpoint<span style="color:#f92672">-</span>hostname;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">SET</span> paimon.fs.obs.<span style="color:#66d9ef">access</span>.<span style="color:#66d9ef">key</span><span style="color:#f92672">=</span>xxx;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">SET</span> paimon.fs.obs.secret.<span style="color:#66d9ef">key</span><span style="color:#f92672">=</span>yyy;
</span></span></code></pre></div><p>And read table from hive metastore, table can be created by Flink or Spark, see <a href="http://localhost:1313/zh/flink/sql-ddl/">Catalog with Hive Metastore</a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> test_table;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">SELECT</span> <span style="color:#66d9ef">COUNT</span>(<span style="color:#ae81ff">1</span>) <span style="color:#66d9ef">FROM</span> test_table;
</span></span></code></pre></div></div></div>

</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#supported-filesystems">Supported FileSystems</a></li>
    <li><a href="#dependency">Dependency</a></li>
    <li><a href="#hdfs">HDFS</a>
      <ul>
        <li><a href="#hdfs-configuration">HDFS Configuration</a></li>
        <li><a href="#hadoop-compatible-file-systems-hcfs">Hadoop-compatible file systems (HCFS)</a></li>
        <li><a href="#kerberos">Kerberos</a></li>
        <li><a href="#hdfs-ha">HDFS HA</a></li>
        <li><a href="#hdfs-viewfs">HDFS ViewFS</a></li>
      </ul>
    </li>
    <li><a href="#oss">OSS</a></li>
    <li><a href="#s3">S3</a>
      <ul>
        <li><a href="#s3-compliant-object-stores">S3 Compliant Object Stores</a></li>
        <li><a href="#configure-path-style-access">Configure Path Style Access</a></li>
        <li><a href="#s3a-performance">S3A Performance</a></li>
      </ul>
    </li>
    <li><a href="#google-cloud-storage">Google Cloud Storage</a></li>
    <li><a href="#microsoft-azure-storage">Microsoft Azure Storage</a></li>
    <li><a href="#microsoft-azure-storage-1">Microsoft Azure Storage</a></li>
    <li><a href="#obs">OBS</a></li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












